# ğŸ“¡ Despliegue de Pipeline CI/CD en Vertex AI utilizando Google Cloud Platform (GCP): Vertex AI + Cloud Storage + Cloud Build

Este proyecto demuestra cÃ³mo implementar una arquitectura de **CI/CD (IntegraciÃ³n y Despliegue Continuo)** para un pipeline analÃ­tico/predictivo en **Vertex AI**, 
utilizando servicios nativos de **Google Cloud Platform** como **Cloud Storage** y **Cloud Build**.

---

## ğŸš€ Arquitectura General

La soluciÃ³n sigue la siguiente arquitectura:

1. El desarrollo del pipeline se realiza localmente o desde Vertex AI Workbench.
2. Al realizar un `git push` a una rama especÃ­fica del repositorio en GitHub, se activa un **Trigger de Cloud Build**.
3. **Cloud Build** compila y ejecuta automÃ¡ticamente el pipeline definido en el archivo `pipeline.py`.
4. El pipeline puede consumir datos desde un bucket en **Cloud Storage**.

---

## ğŸ§± Servicios Utilizados

| Servicio GCP       | Rol en la Arquitectura                                                                 |
|--------------------|----------------------------------------------------------------------------------------|
| **Vertex AI**      | Desarrollo del pipeline analÃ­tico/predictivo                                           |
| **Cloud Storage**  | Almacenamiento de datos fuente (e.g., `data.csv`) utilizados por el pipeline           |
| **Cloud Build**    | EjecuciÃ³n automatizada del pipeline al realizar `push` en GitHub (CI/CD)               |

---

## ğŸ“ Estructura del Repositorio

ğŸ“¦ vertex-ai-cicd
â”œâ”€â”€ pipeline.py # CÃ³digo del pipeline predictivo
â”œâ”€â”€ requirements.txt # Dependencias Python necesarias
â”œâ”€â”€ data.csv # Archivo de entrada almacenado en GCS
â””â”€â”€ cloudbuild.yaml # Script de construcciÃ³n para Cloud Build



---

## ğŸ§ª Componentes del Proyecto

### 1. Vertex AI - `pipeline.py`

- CÃ³digo principal del pipeline que realiza anÃ¡lisis o predicciones.
- Debe estar preparado para ejecutarse sin intervenciÃ³n manual (automatizable).

### 2. Cloud Storage - `data.csv`

- Contiene los datos de entrada del pipeline.
- AsegÃºrate de subir este archivo al bucket correspondiente y actualizar la ruta en el cÃ³digo.

### 3. Cloud Build - `cloudbuild.yaml`

- Orquestador que ejecuta el pipeline automÃ¡ticamente.
- Se activa con un trigger al hacer `push` en la rama configurada de GitHub.



---

## âœ… Pre-requisitos

AsegÃºrate de cumplir con los siguientes pasos antes de ejecutar el pipeline:

### ğŸ”Œ Servicios habilitados en GCP

- [x] **Vertex AI**
- [x] **Cloud Build**
- [x] **Cloud Storage**
- [ ] **Artifact Registry** *(opcional, solo si usas imÃ¡genes personalizadas)*

### ğŸ“‚ Cloud Storage

- [x] Crear un **bucket** en Cloud Storage.
- [x] Subir el archivo `data.csv` al bucket correspondiente.
- [x] Verifica que la ruta usada en el script `pipeline.py` apunte correctamente al archivo en el bucket.

### ğŸ” Trigger de Cloud Build

- [x] Crear un **trigger de compilaciÃ³n** con las siguientes configuraciones:
  - **Tipo**: GitHub
  - **Evento**: Push a una rama especÃ­fica (por ejemplo, `main`)
  - **UbicaciÃ³n del archivo YAML**: RaÃ­z del repositorio (`cloudbuild.yaml`)

### ğŸ” Permisos de la cuenta de servicio (IAM)

AsegÃºrate de que la cuenta de servicio usada por **Cloud Build** tenga los siguientes roles asignados:

- `roles/storage.objectViewer` â†’ Permite leer archivos del bucket
- `roles/aiplatform.user` â†’ Permite ejecutar recursos en Vertex AI
- `roles/cloudbuild.builds.editor` â†’ Permite ejecutar y gestionar builds

---

## ğŸš€ EjecuciÃ³n

Una vez que todo estÃ¡ configurado correctamente, realiza lo siguiente:

### 1. Modifica tu archivo local

Haz cambios en `pipeline.py` o cualquier otro componente del proyecto.

### 2. Realiza un commit y push

```bash
git add .
git commit -m "Update pipeline"
git push origin main



---

## âœ… Resultado Esperado

Al ejecutar el `git push`, se espera lo siguiente:

- ğŸš€ Se activa el **trigger de Cloud Build** configurado previamente.
- ğŸ§  El archivo `pipeline.py` es ejecutado como parte del proceso de compilaciÃ³n en Vertex AI.
- â˜ï¸ El pipeline consume el archivo `data.csv` directamente desde **Cloud Storage**.
- ğŸ” Los resultados del pipeline estarÃ¡n disponibles desde:
  - ğŸ“Š La consola de **Vertex AI**
  - ğŸ“ Los registros en **Cloud Logging**
  - ğŸ“ Cualquier salida definida dentro del script (`print()`, `logging`, etc.)

---




